---
layout: posts
title:  "Inteligência Artificial Explicável aplicada a detecção de desinformação"
date:   2020-12-01 16:16:32 -0600
categories: trabalho
autornick: PedroLS
autor: "Pedro Lamkowski dos Santos"
orientador: "Prof. Dr. João Paulo Papa. Coorientador: Gustavo Henrique Rosa"
---
Atualmente, a internet possibilitou a conexão de pessoas ao redor do mundo e se tornou o principal meio de consumo e produção de informações. Porém, devido a sua velocidade de produção e grande quantidade de informações, muitos artigos e, principalmente, publicações em redes sociais contendo desinformações são propagados com rapidez. Com isso, diversos modelos de Inteligência Artificial para classificação de notícias falsas e desinformação foram estudados e elaborados, trazendo diversos resultados promissores. Entretanto, ainda faltam estudos que expliquem os motivos da classificação, ou seja, a explicabilidade desses modelos. A grande maioria de modelos estruturados como redes neurais são obscuros, ou seja, não é possível determinar os motivos que levaram à tomada de decisões. Este projeto buscou utilizar dois modelos de Aprendizado de Máquina com arquiteturas simples para essa tarefa de classificação com o intuito de explicar suas decisões. Para isso, foram utilizadas duas abordagens de explicabilidade: uma inerente do modelo de classificação e uma post-hoc. Foram testados dois conjuntos de dados, LIAR e FNID, que consistem de declarações relacionadas a figuras e acontecimentos políticos rotuladas pela sua veracidade. Por fim, é visualizado utilizando exemplos como certos vieses podem afetar as decisões de modelos mais simples. 
